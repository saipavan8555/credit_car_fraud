# -*- coding: utf-8 -*-
"""credit card  _ Fraud detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lNOFmEnRX_UD536NdpjOxrZzPbujkxn_
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

df= pd. read_csv('/content/drive/MyDrive/ml/Problem1_Data.csv')

df.shape

df

df.isna().sum(axis=0)

df.describe()

df['Class'].value_counts()

df['Time'].value_counts()

pd.value_counts('class',normalize=True)*100

df.columns

df_label= df['Time'].astype

df.drop('Time', axis=1,inplace=True)

df.columns

df.describe()

df.dtypes

for col in ['Class']:
  df[col]=df[col].astype('category')
#df[col]=df[col].astype('category')

df.dtypes
df.dtypes

cat_col= df.select_dtypes(include=['category']).columns#2132134`4```````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````````533333333333333333333333333333333333334444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444`ERWQDSAVXz

#df = pd.get_dummies(columns=cat_col, data=df, 
 #                     prefix=cat_col, prefix_sep="_", drop_first=True)

df.head()

df['Class'].value_counts()

df['Class'].value_counts(normalize=True)*100



num_col=df.select_dtypes(include=['float','int'])

num_col.columns

#df=pd.concat([cat_col,num_col],axis=1,join='inner')

df

from sklearn.model_selection import train_test_split

x=df.drop('Class',axis=1)
y= df['Class']

x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.3,stratify=y,random_state=1673)

x_train.columns

print(x_train.shape)
print(x_val.shape)
print(y_train.shape)
print(y_val.shape)

print(pd.value_counts(y_train,normalize=True)*100)

print(pd.value_counts(y_val,normalize=True)*100)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler

num_cols=x_train.select_dtypes(include=['int','float']).columns

num_cols

#scaler.fit(x_train[num_cols])

from sklearn.preprocessing import StandardScaler
    #from sklearn.preprocessing import MinMaxScaler
    scaler = StandardScaler()
    scaler.fit(x_train[num_cols])
    x_train[num_cols]=scaler.transform(x_train[num_cols])
    x_val[num_cols]=scaler.transform(x_val[num_cols])

x_train.head()

from sklearn.tree import DecisionTreeClassifier, export_graphviz

from sklearn.model_selection import GridSearchCV

from sklearn.metrics import confusion_matrix,  accuracy_score,recall_score,precision_score

model1=DecisionTreeClassifier

#model1.fit(x_train, y_train)

model1 = DecisionTreeClassifier()

model1.fit(x_train, y_train)

importances= model1.feature_importances_
importances

# its make the all important features in the aasending order
indices = np.argsort(importances)[::-1]
ind_name=x_train.columns
pd.DataFrame([ind_name[indices],np.sort(importances)[::-1]])

model1.classes_

import graphviz

visullization = export_graphviz(model1, feature_names= ind_name,class_names=['No','Yes'],filled=True)

graph= graphviz.Source(visullization)

graph.render("ClassTree")

model2= DecisionTreeClassifier(max_depth=3)
model2.fit(x_train, y_train)
visullization2 = export_graphviz(model2, feature_names=ind_name,class_names=["No","Yes"],filled=True)
graph2= graphviz.Source(visullization2)
graph2

model7= DecisionTreeClassifier(max_depth=3)
model1.fit(x_train, y_train)
visullization3 = export_graphviz(model1, feature_names=ind_name,class_names=["No","Yes"],filled=True)
graph3= graphviz.Source(visullization3)
graph3

# lets predict model

train_pred= model1.predict(x_train)
val_pred= model1.predict(x_val)

confusion_matrix(y_train,train_pred)

def error_matrix(act,pred):
  print(confusion_matrix(act,pred))
  print(accuracy_score(act,pred))
  print(recall_score(act,pred))
  print(precision_score(act,pred))

error_matrix(y_train,train_pred)

error_matrix(y_val,val_pred)

# there is an bias in the model as it have ther class imbalance 
# there are more values of the non fraud almost of 99% are non fraud and only one precnt is fraud\

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=123)

re_x_train, re_y_train= smote.fit_resample(x_train, y_train)

print(re_x_train.shape)
print(x_train.shape)

print(re_y_train.shape)
print(y_train.shape)

print(pd.value_counts(re_y_train,normalize=True)*100)
print(pd.value_counts(y_train, normalize=True)*100)

model3= DecisionTreeClassifier()

model3= model3.fit(re_x_train,re_y_train)

importance1= model3.feature_importances_
importance1

ind= np.argsort(importance1)[::-1]
# ind_name refers tp the x_train .columns
pd.DataFrame([ind_name[ind], np.sort(importance1)[::-1]])

train_pred1= model3.predict(re_x_train)
val_pred1= model3.predict(x_val)
# here we use x_val bcz there is no num columns in the val there is only of the target values

error_matrix(re_y_train,train_pred1)

error_matrix(y_val,val_pred1)

# previous without smote
print(error_matrix(y_val,val_pred))
#print(error_matrix(x_train, train_pred))

par_grid = {"criterion": ["gini", "entropy"],
              "min_samples_split": [3, 5],
              "max_depth": [3, 2],
              "min_samples_leaf": [2, 5]
             }

model4 = DecisionTreeClassifier()

model4_grid= GridSearchCV(model4, par_grid, cv=4)

model4_grid.fit(re_x_train,re_y_train)

model4_grid.best_params_

train_pred2= model4_grid.predict(re_x_train)
val_pred2=model4_grid.predict(x_val)

error_matrix(re_y_train, train_pred2)

error_matrix(y_val,val_pred2)

importance3=model4_grid.best_estimator_.feature_importances_
importance3

indices1= np.argsort(importance3)[::-1]
print(indices1)

select= indices1[0:5]
print(select)

#model8 = DecisionTreeClassifier()

#model8_grid= GridSearchCV(model3, par_grid, cv=6)

#@model8_grid.fit(re_x_train,re_y_train)

#model8_grid.best_params_

#train_pred8= model8_grid.predict(re_x_train)
#val_pred8=model8_grid.predict(x_val)

#error_matrix(re_y_train, train_pred8)

#error_matrix(y_val,val_pred8)

#importance8=model8_grid.best_estimator_.feature_importances_
#importance8

#indices8= np.argsort(importance8)[::-1]
#print(indices8)

#select8= indices1[0:5] 
#print(select8)



model5= DecisionTreeClassifier(criterion='entropy', max_depth=None,min_samples_leaf=1,min_samples_split=2)

model5= model5.fit(re_x_train.values[:,select],re_y_train)

train_pred3= model5.predict(re_x_train.values[:,select])
val_pred3= model5.predict(x_val.values[:,select])

error_matrix(re_y_train,train_pred3)

error_matrix(y_val,val_pred3)

model_5= DecisionTreeClassifier(max_depth=3)
model_5.fit(re_x_train, re_y_train)
visullization3 = export_graphviz(model_5, feature_names=ind_name,class_names=["No","Yes"],filled=True)
graph3= graphviz.Source(visullization3)
graph3



## logestic regression

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import accuracy_score,recall_score,precision_score
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.naive_bayes import MultinomialNB 
from sklearn.naive_bayes import GaussianNB 
# %matplotlib inline
import statsmodels.api as sm

x_train

"""**# logestic regression**:"""

y_train

x_train = sm.add_constant(x_train)
x_val = sm.add_constant(x_val)

model1=sm.Logit(y_train,x_train)
model1=model1.fit()
print(model1.summary2())

logit_model2= LogisticRegression(penalty='none')
logit_model2.fit(x_train,y_train)

### there is an imbalance in the data set we should smote them as making them 50/50 ratio

print('before smote')
print(x_train.shape)
print(y_train.shape)
print('after smote')
print(re_x_train.shape)
print(re_y_train.shape)

sm_x_train = sm.add_constant(re_x_train)
x_val = sm.add_constant(x_val)

logit_model3=sm.Logit(re_y_train,sm_x_train)
logit_model3=logit_model3.fit()
print(logit_model3.summary2())

logistic_model4 = LogisticRegression(penalty='none')

logistic_model4.fit(sm_x_train,re_y_train)

train_preds = logistic_model4.predict(sm_x_train)
train_preds_prob=logistic_model4.predict_proba(sm_x_train)[:,1]
test_preds = logistic_model4.predict(x_val)
test_preds_prob=logistic_model4.predict_proba(x_val)[:,1]

train_pred

logistic_model4.coef_

error_matrix(re_y_train,train_preds)

error_matrix(y_val,test_preds)

print(classification_report(re_y_train,train_preds))

print(classification_report(y_val,test_preds))

fpr, tpr, threshold= roc_curve(re_y_train, train_preds_prob)
roc_auc= auc(fpr, tpr)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib notebook
plt.plot([0,1],[0,1],color='navy', lw=2, linestyle='--')
plt.plot(fpr,tpr,color='orange', lw=3, label='ROC curve (area = %0.2f)' % roc_auc)

plt.xlabel('FPR')
plt.ylabel('TPR')
plt.legend(loc="lower right")

roc_df = pd.DataFrame({'FPR':fpr, 'TPR':tpr, 'Threshold':threshold})

roc_df

roc_df.sort_values('TPR', ascending=False,inplace=True)

optimal_indx= np.argmax(tpr- fpr)
optimal_threshold= threshold[optimal_indx]

optimal_threshold

custom_threshold = 0.366
final_pred_array = pd.Series([0 if x>custom_threshold else 1 for x in train_preds_prob])
final_pred_array.value_counts()

final_test_pred_array = pd.Series([0 if x>custom_threshold else 1 for x in test_preds_prob])
final_test_pred_array.value_counts()

## To get True-False format vector (pandas Series)
final_pred = pd.Series(train_preds_prob > 0.366)
final_pred.value_counts()
final_test_pred=pd.Series(test_preds_prob > 0.366)

print(classification_report(re_y_train, final_pred))

print(classification_report(y_val, final_test_pred))

print(error_matrix(re_y_train,final_pred))
print(error_matrix(y_val,final_test_pred))

